{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df1017-6353-4821-885e-5d13a24b3326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c14a15-07a5-4366-99a7-daa6c7f64952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (tanh): Tanh()\n",
      "  (output): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "Epoch [100/1000], Loss: 0.2418\n",
      "Epoch [200/1000], Loss: 0.2397\n",
      "Epoch [300/1000], Loss: 0.2379\n",
      "Epoch [400/1000], Loss: 0.2363\n",
      "Epoch [500/1000], Loss: 0.2349\n",
      "Epoch [600/1000], Loss: 0.2337\n",
      "Epoch [700/1000], Loss: 0.2326\n",
      "Epoch [800/1000], Loss: 0.2315\n",
      "Epoch [900/1000], Loss: 0.2306\n",
      "Epoch [1000/1000], Loss: 0.2297\n",
      "Outputs:\n",
      "tensor([[0.3649],\n",
      "        [0.3952],\n",
      "        [0.3773],\n",
      "        [0.4025]], grad_fn=<SigmoidBackward0>)\n",
      "Overall Accuracy: 75.00%\n",
      "Layer: hidden.weight, Weights: tensor([[ 0.3911,  0.0205],\n",
      "        [-0.6516, -0.3549],\n",
      "        [ 0.1180,  0.4937]])\n",
      "Layer: hidden.bias, Weights: tensor([0.2549, 0.2183, 0.2098])\n",
      "Layer: output.weight, Weights: tensor([[-0.2181, -0.1647,  0.1885]])\n",
      "Layer: output.bias, Weights: tensor([-0.5035])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 3)),      # first hidden layer with 4 neurons\n",
    "    ('tanh', nn.Tanh()),              # Tanh activation function\n",
    "    # ('hidden2', nn.Linear(3, 4)),     # second hidden layer with 4 neurons\n",
    "    # ('relu', nn.ReLU()),              # ReLU activation function\n",
    "    ('output', nn.Linear(3, 1)),      # output layer with 1 neuron\n",
    "    ('sigmoid', nn.Sigmoid())         # sigmoid activation function\n",
    "]))\n",
    "print(model)\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in)\n",
    "\n",
    "data_target1 = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float)\n",
    "print(data_target1)\n",
    "\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the number of epochs for training\n",
    "num_epochs = 1000\n",
    "\n",
    "# Lists to store loss values for visualization\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(data_in)\n",
    "    loss = criterion1(outputs, data_target1)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    # Store the loss value for visualization\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print('Outputs:')\n",
    "print(outputs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = torch.round(model(data_in))\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = (predictions.squeeze() == data_target1[:, 0]).sum().item()\n",
    "total_samples = len(data_target1)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "# Print accuracy\n",
    "print(f'Overall Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "# Print model weights\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f'Layer: {name}, Weights: {param.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ea8e82f-e100-4eb4-9051-45b686378f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (output): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (tanh): Tanh()\n",
      ")\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "Epoch [100/1000], Loss: 0.2507\n",
      "Epoch [200/1000], Loss: 0.2505\n",
      "Epoch [300/1000], Loss: 0.2505\n",
      "Epoch [400/1000], Loss: 0.2505\n",
      "Epoch [500/1000], Loss: 0.2504\n",
      "Epoch [600/1000], Loss: 0.2504\n",
      "Epoch [700/1000], Loss: 0.2504\n",
      "Epoch [800/1000], Loss: 0.2503\n",
      "Epoch [900/1000], Loss: 0.2503\n",
      "Epoch [1000/1000], Loss: 0.2503\n",
      "Outputs:\n",
      "tensor([[0.4934],\n",
      "        [0.4919],\n",
      "        [0.5076],\n",
      "        [0.5070]], grad_fn=<TanhBackward0>)\n",
      "Overall Accuracy: 75.00%\n",
      "Layer: hidden.weight, Weights: tensor([[ 0.2844, -0.6668],\n",
      "        [ 0.1879,  0.4461],\n",
      "        [-0.3852,  0.3811]])\n",
      "Layer: hidden.bias, Weights: tensor([0.6907, 0.6839, 0.3660])\n",
      "Layer: output.weight, Weights: tensor([[0.2926, 0.3589, 0.1376]])\n",
      "Layer: output.bias, Weights: tensor([0.0259])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 3)),      # first hidden layer with 2 neurons\n",
    "    ('sigmoid', nn.Sigmoid()),        # sigmoid activation function\n",
    "    ('output', nn.Linear(3, 1)),     # second hidden layer with 1 neurons\n",
    "    ('tanh', nn.Tanh())           # Tanh activation function\n",
    "    \n",
    "]))\n",
    "print(model)\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in)\n",
    "\n",
    "data_target1 = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float)\n",
    "print(data_target1)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the number of epochs for training\n",
    "num_epochs = 1000\n",
    "\n",
    "# Lists to store loss values for visualization\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(data_in)\n",
    "    loss = criterion1(outputs, data_target)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    # Store the loss value for visualization\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print('Outputs:')\n",
    "print(outputs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = torch.round(model(data_in))\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = (predictions.squeeze() == data_target1[:, 0]).sum().item()\n",
    "total_samples = len(data_target1)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "# Print accuracy\n",
    "print(f'Overall Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print model weights\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f'Layer: {name}, Weights: {param.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed800587-1633-44ef-8854-de7aa7f11ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "Epoch [100/1000], Loss: 0.6711\n",
      "Epoch [200/1000], Loss: 0.6621\n",
      "Epoch [300/1000], Loss: 0.6539\n",
      "Epoch [400/1000], Loss: 0.6456\n",
      "Epoch [500/1000], Loss: 0.6367\n",
      "Epoch [600/1000], Loss: 0.6270\n",
      "Epoch [700/1000], Loss: 0.6168\n",
      "Epoch [800/1000], Loss: 0.6060\n",
      "Epoch [900/1000], Loss: 0.5947\n",
      "Epoch [1000/1000], Loss: 0.5827\n",
      "Outputs:\n",
      "tensor([[0.3681],\n",
      "        [0.5269],\n",
      "        [0.5542],\n",
      "        [0.4732]], grad_fn=<SigmoidBackward0>)\n",
      "Overall Accuracy: 25.00%\n",
      "Layer: hidden.weight, Weights: tensor([[ 0.0751,  0.5791],\n",
      "        [-0.0290, -0.1753],\n",
      "        [-0.7937, -0.7929],\n",
      "        [ 0.4963,  0.4002]])\n",
      "Layer: hidden.bias, Weights: tensor([-0.0752,  0.4792,  0.7933, -0.3999])\n",
      "Layer: output.weight, Weights: tensor([[-0.2243,  0.2330, -1.0129, -0.3868]])\n",
      "Layer: output.bias, Weights: tensor([0.1502])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 4)),      # first hidden layer with 4 neurons\n",
    "    ('relu', nn.ReLU()),              # ReLU activation function\n",
    "    ('output', nn.Linear(4, 1)),      # output layer with 1 neuron\n",
    "    ('sigmoid', nn.Sigmoid())         # sigmoid activation function\n",
    "]))\n",
    "print(model)\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in)\n",
    "data_target1 = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float)\n",
    "print(data_target1)\n",
    "\n",
    "\n",
    "criterion1 = nn.BCELoss()\n",
    "optimizer1 = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the number of epochs for training\n",
    "num_epochs = 1000\n",
    "\n",
    "# Lists to store loss values for visualization\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(data_in)\n",
    "    loss = criterion1(outputs, data_target)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    # Store the loss value for visualization\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print('Outputs:')\n",
    "print(outputs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = torch.round(model(data_in))\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = (predictions.squeeze() == data_target1[:, 0]).sum().item()\n",
    "total_samples = len(data_target1)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "# Print accuracy\n",
    "print(f'Overall Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "# Print model weights\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f'Layer: {name}, Weights: {param.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390171e-d0b7-47e6-b917-aca99d15c8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4ea31-7f11-4c3a-9ab9-307aea297f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
